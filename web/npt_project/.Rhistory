participant_data <- read.csv("data/raw/participant1.csv")
getwd()
## 1) Parse the JSON string into an R object
##    Use jsonlite::fromJSON() to convert the text into a list.
## Example:
responses <- fromJSON(json_string)
library(readr)
npt_experiment_2025_11_05_10_33_05 <- read_csv("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
View(npt_experiment_2025_11_05_10_33_05)
View(npt_experiment_2025_11_05_10_33_05)
## 1) Parse the JSON string into an R object
##    Use jsonlite::fromJSON() to convert the text into a list.
## Example:
responses <- fromJSON(json_string)
getwd()
participant_data <- read.csv("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
View(participant_data)
## 1) Parse the JSON string into an R object
##    Use jsonlite::fromJSON() to convert the text into a list.
## Example:
responses <- fromJSON(participant_data[participant_data$trialType == "questionnaire",
"response"])
#### score_questionnaire.R -----------------------------------------------------
library("jsonlite")
## 1) Parse the JSON string into an R object
##    Use jsonlite::fromJSON() to convert the text into a list.
## Example:
responses <- fromJSON(participant_data[participant_data$trialType == "questionnaire",
"response"])
View(responses)
## 2) Flatten and convert to numeric
##    Use unlist() to turn the list into a vector and coerce to numeric if needed.
## Example:
responses <- as.numeric(unlist(responses))
responses
View(participant_data)
## 3) Reverse-score the specified items
rev_items <- c(2, 4, 7)
responses[rev_items] <- 4 - responses[rev_items]
## 5) Compute the final score
mean_score <- mean(responses, na.rm = TRUE)
#### Score Behavioral Data ------------------------------------
## Separate data into block and trial types
practice_filtered  <- participant_data[participant_data$block == "practice", ]
magnitude_filtered <- participant_data[participant_data$block == "experiment" & participant_data$trial_type == "magnitude", ]
parity_filtered    <- participant_data[participant_data$block == "experiment" & participant_data$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= 250 & practice_filtered$rt  <= 900, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= 250 & magnitude_filtered$rt <= 900, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= 250 & parity_filtered$rt    <= 900, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
View(participant_data)
View(practice_filtered)
#### Score Behavioral Data ------------------------------------
## Change correct column into logical
participant_data$correct <- as.logical(participant_data$correct)
## Separate data into block and trial types
practice_filtered  <- participant_data[participant_data$block == "practice", ]
magnitude_filtered <- participant_data[participant_data$block == "experiment" & participant_data$trial_type == "magnitude", ]
parity_filtered    <- participant_data[participant_data$block == "experiment" & participant_data$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= 250 & practice_filtered$rt  <= 900, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= 250 & magnitude_filtered$rt <= 900, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= 250 & parity_filtered$rt    <= 900, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
## Get subject ID
file_path  <- "psy1903/web/npt_project/data/raw/npt-experiment-2025-11-05-12-34-56.csv"
subject_id <- sub("\\.csv$", "", basename(file_path))
## One-row summary for this participant
participant_summary <- data.frame(
subject_id         = subject_id,
tef10_score        = mean_score,
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
participant_summary
View(participant_summary)
dir.create("data/cleaned/participants", recursive = TRUE)
#### Score Behavioral Data ------------------------------------
summarize_behavior <- function(df, rt_min=250, rt_max=900) {
# Ensure all expected column names are there
if (!all(c("block", "rt", "correct") %in% names(df)) ||
!any(c("trial_type", "trialType") %in% names(df))) {
stop("Input data frame is missing required columns.")
}
## Check if rt column is numeric
if (!is.numeric(df$rt)) {
df$rt <- as.numeric(df$rt)
warning("'rt' column was not numeric. Coerced with as.numeric().")
}
## Change correct column to logical
if (!is.logical(df$correct)) {
df$correct <- as.logical(df$correct)
}
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min & practice_filtered$rt  <= rt_max, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= rt_min & magnitude_filtered$rt <= rt_max, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= rt_min & parity_filtered$rt    <= rt_max, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
## One-row summary for this participant
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
# Accuracy 0..1
acc_cols <- c("practice_acc", "magnitude_acc", "parity_acc")
for (col in acc_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < 0 || val > 1)) {
warning(paste(col, "is outside [0, 1]. Check 'correct' coding."))
}
}
# Mean RTs within [rt_min, rt_max]
rt_cols <- c("practice_mean_rt", "magnitude_mean_rt", "parity_mean_rt")
for (col in rt_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < rt_min || val > rt_max)) {
warning(paste(col, "is outside [", rt_min, ", ", rt_max, "]."))
}
}
return(participant_summary)
}
summarize_behavior(participant_data)
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
View(behavior)
View(participant_data)
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
traceback()
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
getwd()
getwd()
getwd()
gewd()
getwd()
getwd()
getwd()
---
title: "Processing Individual Participant"
getwd()
here::here()
here()
library(here)
here()
here()
library(here)
here()
setwd("C:/Users/mayak/Desktop/psy1903/web/npt_project")
getwd()
file.create(".here")
getwd()
file.create("reports/npt_group.qmd")
# Load here::here robustly
if (!require(here)) install.packages("here")
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
getwd()
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
## Replace Column Names
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
View(study_level)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_acc - study_level$magnitude_acc
getwd()
# Create full project folder structure under psy1903/web/
setwd("C:/Users/mayak/Desktop/psy1903") # Update to your path
dir.create("web/w11_taskset/data/raw", recursive = TRUE, showWarnings = FALSE)
dir.create("web/npt_project/data/cleaned", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/scripts", recursive = TRUE, showWarnings = FALSE)
dir.create("web/w11_taskset/reports", recursive = TRUE, showWarnings = FALSE)
# Create placeholder R Script and Quarto Report files
file.create("web/w11_taskset/scripts/score_questionnaire.R")
file.create("web/w11_taskset/scripts/process_participant.R")
file.create("web/w11_taskset/reports/npt_import.qmd")
getwd()
file.create(here::here("scripts/npt_dataviz.qmd"))
p_load("ggplot2")
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
npt_data <- read.csv(here::here("data/cleaned/study_level_processed.csv"))
getwd()
setwd("C:/Users/mayak/Desktop/psy1903/web/npt_project")
npt_data <- read.csv(here::here("data/cleaned/study_level_processed.csv"))
npt_data <- read.csv(here::here("data/cleaned/study_level.csv"))
dir.create(here::here("output/plots"), recursive = TRUE, showWarnings = FALSE)
#| label: fig-example
#| fig-cap: "Example figure caption generated by Quarto."
plot(1:10, 1:10)
ggplot(data_frame, aes(x = variable_x, y = variable_y)) +
geom_layer()
library(ggplot2)
comp_likelihood_ratio <- function (var1_blue_prop,
var2_blue_prop,
red_prop,
samples){
out <- data.frame(
sample = samples,
var1_like = NA,
var2_like = NA,
like_ratio = NA
)
for (i in seq_along(samples) ){
s <- samples[i]
if (s == "blue") {
var1_like <- (1 - red_prop) * var1_blue_prop[i]
var2_like <- (1 - red_prop) * var2_blue_prop[i]
} else if (s == "yellow") {
var1_like <- (1 - red_prop) * (1 - var1_blue_prop[i])
var2_like <- (1 - red_prop) * (1 - var2_blue_prop[i])
} else if (s == "red") {
var1_like <- red_prop
var2_like <- red_prop
}
out$var1_like[i] <- var1_like
out$var2_like[i] <- var2_like
out$like_ratio[i] <- var1_like / var2_like
}
return(out)
}
library(dplyr)
library(purrr)
library(tibble)
library(stringr)
comp_likelihood_ratio <- function(var1_blue_prop, var2_blue_prop,
red_prop = 0.2, samples) {
tibble(
sample = samples
) %>%
mutate(
var1_like = case_when(
sample == "red"    ~ red_prop,
sample == "blue"   ~ (1 - red_prop) * var1_blue_prop,
sample == "yellow" ~ (1 - red_prop) * (1 - var1_blue_prop)
),
var2_like = case_when(
sample == "red"    ~ red_prop,
sample == "blue"   ~ (1 - red_prop) * var2_blue_prop,
sample == "yellow" ~ (1 - red_prop) * (1 - var2_blue_prop)
),
like_ratio = var1_like / var2_like
)
}
seqs <- list(
seq1 = c("red", "blue", "yellow", "yellow"),
seq2 = c("blue", "blue", "red"),
seq3 = c("yellow", "yellow", "blue", "red", "blue")
)
params <- tibble(
param_id = 1:3,
var1_blue_prop = c(0.2, 0.5, 0.8),
var2_blue_prop = c(0.7, 0.4, 0.3)
)
View(params)
library(tidyr)
results <- crossing(
seq_id = names(seqs),
params
) %>%
mutate(
samples = map(seq_id, ~ seqs[[.x]]),
out = pmap(
list(var1_blue_prop, var2_blue_prop, samples),
~ comp_likelihood_ratio(..1, ..2, red_prop = 0.2, samples = ..3)
)
) %>%
unnest(out)
View(params)
